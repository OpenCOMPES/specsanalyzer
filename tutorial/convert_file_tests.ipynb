{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864500e2",
   "metadata": {},
   "source": [
    "TEST LOADER FOR PHOIBOS 150 DATA\n",
    "\n",
    "Typical structure \n",
    "/2020/01 January/Day 10/Raw Data/8874\n",
    "\n",
    "Withing the folder of the scan number there is an info.txt and a scan\n",
    "In THE AVG FOLDER there is a set of images, averaged over every acquisition cycle\n",
    "IN THE RAW FOLDER there are single acquisition cycles (difference: in EPFL we added the \"save every n cycle function\"\n",
    "this RAW folder also contains a \"LUT.txt\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fafb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the os package\n",
    "import os\n",
    "\n",
    "#get current directory\n",
    "workingdir=os.getcwd()\n",
    "#print(workingdir)\n",
    "#navigate to example data\n",
    "exampledatapath=os.path.realpath(os.path.join(workingdir, '..','tests\\data\\dataEPFL\\\\2020\\\\02 February\\Day 17\\Raw Data\\9159'))\n",
    "filelist=os.listdir(exampledatapath)\n",
    "print(\"example data path= \",exampledatapath)\n",
    "#this folders contains the AVG folder with the data, an info.txt vector and a scan vector\n",
    "#filelist\n",
    "\n",
    "#navigate to the image folder, for EPFL in the \\AVG subfolder of the data (note that single scan cycles for partial load are in another subfolder - to be checked with Laurenz)\n",
    "avgimagepath=os.path.realpath(os.path.join(workingdir, '..','tests\\data\\dataEPFL\\\\2020\\\\02 February\\Day 17\\Raw Data\\9159\\AVG'))\n",
    "print(\"AVG images path= \",avgimagepath)\n",
    "rawimagelist=os.listdir(avgimagepath)\n",
    "#alternatively join the paths\n",
    "#avgimagepath=os.path.join(exampledatapath,'AVG') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fname=os.path.join(avgimagepath,rawimagelist[0]) \n",
    "numpy_array = np.loadtxt(fname, delimiter=\"\\t\")\n",
    "\n",
    "h = plt.contourf(numpy_array)\n",
    "plt.colorbar()\n",
    "#plt.xlim(120,150)\n",
    "#plt.ylim(150,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af24f0e",
   "metadata": {},
   "source": [
    "one of the first operations should be to filter the image to remove the grid via FFT filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61888c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the module and import functions for reading the parameter table from the calib2d file\n",
    "from importlib import reload\n",
    "import specsanalyzer.convert\n",
    "from specsanalyzer.convert import parameters_table\n",
    "reload(specsanalyzer.convert)\n",
    "from specsanalyzer.convert import GetParameters\n",
    "reload(specsanalyzer.convert)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE CALIBRATION FILE NAME FROM THE EXAMPLE FOLDER\n",
    "calib2dfilename=os.path.realpath(os.path.join(workingdir, '..','tests\\data\\dataEPFL\\phoibosEPFL.txt'))\n",
    "#GET THE INFO FILE NAME FROM THE EXAMPLE FOLDER, SCAN 9159\n",
    "#navigate to example data\n",
    "exampledatapath=os.path.realpath(os.path.join(workingdir, '..','tests\\data\\dataEPFL\\\\2020\\\\02 February\\Day 17\\Raw Data\\9159'))\n",
    "filelist=os.listdir(exampledatapath)\n",
    "str_match = list(filter(lambda x: 'info.txt' in x, filelist))\n",
    "infofilename=os.path.join(exampledatapath,str_match[0]) \n",
    "\n",
    "calibrationmatrixfull=parameters_table(calib2dfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ac5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrationmatrixinterp=GetParameters(infofilename,calib2dfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75093601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make and test the  polynomial fit\n",
    "ek=10\n",
    "ep=20\n",
    "eshift=np.array([-0.05,0,0.05])\n",
    "currentdamatrix=calibrationmatrixinterp\n",
    "print(type(eshift))\n",
    "da_energy=eshift*ep+ek*np.ones(eshift.shape)\n",
    "\n",
    "def calculate_polynomial_Coef_Da(ek,ep,eshift,currentdamatrix):\n",
    "    \n",
    "    #get the Das from the damatrix\n",
    "    #da1=currentdamatrix[0][:]\n",
    "    #da3=currentdamatrix[1][:]\n",
    "    #da5=currentdamatrix[2][:]\n",
    "    #da7=currentdamatrix[3][:]\n",
    "\n",
    "    #calcualte the energy values for each da, given the eshift\n",
    "    da_energy=eshift*ep+ek*np.ones(eshift.shape)\n",
    "\n",
    "    #create the polinomial coeffiecient matrix, each is a third order polinomial \n",
    "    \n",
    "    dapolymatrix=np.zeros(currentdamatrix.shape)\n",
    "\n",
    "    for i in range(0,currentdamatrix.shape[0]):\n",
    "        #igor uses the fit poly 3, which should be a parabola\n",
    "        dapolymatrix[i][:]=np.polyfit(da_energy, currentdamatrix[i][:], 2).transpose()\n",
    "    return dapolymatrix\n",
    "\n",
    "dapolymatrix=calculate_polynomial_Coef_Da(ek,ep,eshift,currentdamatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382eff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "polcoef = np.polyfit(da_energy, currentdamatrix[0][:], 2)\n",
    "\n",
    "plt.plot(da_energy,currentdamatrix[0][:])\n",
    "\n",
    "energy_full=np.linspace(ek-ep*0.1,ek+ep*0.1,128)\n",
    "polval=np.polyval(polcoef,energy_full)\n",
    "polval2=np.polyval(dapolymatrix[0][:],energy_full)\n",
    "plt.plot(energy_full,polval)\n",
    "plt.plot(energy_full,polval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822894aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from specsanalyzer.convert import calculate_polynomial_coef_da\n",
    "reload(specsanalyzer.convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dapolymatrix2=calculate_polynomial_coef_da(ek,ep,eshift,currentdamatrix)\n",
    "dapolymatrix-dapolymatrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ba5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now calculate the mcp_position_mm and zinner functions\n",
    "\n",
    "def zinner(ek,angle,dapolymatrix):\n",
    "    #poly(D1, Ek )*(Ang) + 10^-2*poly(D3, Ek )*(Ang)^3 + 10^-4*poly(D5, Ek )*(Ang)^5 + 10^-6*poly(D7, Ek )*(Ang)^7\n",
    "    result=0\n",
    "    for i in range(0,dapolymatrix.shape[0]):\n",
    "        #igor uses the fit poly 3, which should be a parabola\n",
    "        result=result+ 10**(-(2*i))*angle**(1+2*i)*np.polyval(dapolymatrix[i][:],ek)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def zinner_diff(ek,angle,dapolymatrix):\n",
    "    #poly(D1, Ek ) + 3*10^-2*poly(D3, Ek )*(Ang)^2 + 5*10^-4*poly(D5, Ek )*(Ang)^4 + 7*10^-6*poly(D7, Ek )*(Ang)^6\n",
    "    result=0\n",
    "    for i in range(0,dapolymatrix.shape[0]):\n",
    "        #igor uses the fit poly 3, which should be a parabola\n",
    "        result=result+ (2*i+1)*10**(-(2*i))*angle**(2*i)*np.polyval(dapolymatrix[i][:],ek)\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def mcp_position_mm(ek,angle,ainner,dapolymatrix):\n",
    "    \n",
    "    mask=np.greater_equal(np.abs(angle),ainner)\n",
    "   \n",
    "    result=np.zeros(angle.shape)#ideally has to be evaluated on a mesh\n",
    "\n",
    "    result = np.where(mask, zinner(ek,angle,dapolymatrix), np.sign(angle)*zinner(ek,angle,dapolymatrix)+(abs(angle)-ainner)*zinner_diff(ek,angle,dapolymatrix))\n",
    "   \n",
    "    return result\n",
    "#if np.greater_equal(np.abs(angle),ainner) : #values larger than the ainner have a different treatment\n",
    "#    result= zinner(ek,angle,dapolymatrix)\n",
    "#else:\n",
    "#    result= np.sign(angle)*zinner(ek,angle,dapolymatrix) + (abs(angle)-ainner)*zinner_diff(ek,angle,dapolymatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mcp_position_mm(1,1,15,dapolymatrix)\n",
    "\n",
    "angles=np.linspace(-18,18,1024)\n",
    "energies=np.linspace(10,20,2048)\n",
    "\n",
    "ainner=15\n",
    "\n",
    "anglemesh,energymesh=np.meshgrid(angles,energies)\n",
    "testimage=mcp_position_mm(energymesh,anglemesh,15,dapolymatrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(specsanalyzer.convert)\n",
    "from specsanalyzer.convert import mcp_position_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles=np.linspace(-18,18,1024)\n",
    "energies=np.linspace(10,20,2048)\n",
    "\n",
    "ainner=15\n",
    "\n",
    "anglemesh,energymesh=np.meshgrid(angles,energies)\n",
    "\n",
    "testimage=mcp_position_mm(energymesh,anglemesh,15,dapolymatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990491c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.contourf(angles,energies,testimage)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fe1e",
   "metadata": {},
   "source": [
    "// calculates the actual correction matrix\n",
    "function Calculate_MatrixCorrection()\n",
    "\n",
    "\tSetDataFolder root:Data:tmpData:'Analyser':\n",
    "\n",
    "\tNVAR PixelSize, magnification, E_Offset_px, Ang_Offset_px, LensMode, Ek, Ep, De1, aInner\n",
    "\tNVAR EkinLow, EkinHigh, AzimuthLow, AzimuthHigh\n",
    "\tNVAR Binning\n",
    "\tNVAR Edge_pos, Edge_Slope\n",
    "\t\n",
    "\tString Str\n",
    "\t// for full frames, if cropped in program we need to do something else?\n",
    "\tVariable nx_pixel=1376/Binning, ny_pixel=1040/Binning\n",
    "\tMake/O/N=(nx_pixel, ny_pixel) MCP_Position_mm_Matrix=NaN, Angular_Correction=NaN\n",
    "\tMake/O/N=(nx_pixel) w_E, E_Correction=NaN\n",
    "\tMake/O/N=(ny_pixel) w_Ang\n",
    "\n",
    "\tVariable Edge_Coef\n",
    "\t\n",
    "\t// Just linear scaling according to the ranges from the calibration file. What limits are they done for?\n",
    "\t//w_E[] = EkinLow+p/(nx_pixel-1)*(EkinHigh-EkinLow)\n",
    "\t//w_Ang[] = AzimuthLow+p/(ny_pixel-1)*(AzimuthHigh-AzimuthLow)\n",
    "\t// Allow 20% more range\n",
    "\t//w_Ang[] = AzimuthLow*1.2+(p-Ang_Offset_px)/(ny_pixel-1)*(AzimuthHigh-AzimuthLow)*1.2\n",
    "\t// store positions in wave scaling of AngularCorrection now!\n",
    "\tsetscale/P x, EkinLow, (EkinHigh-EkinLow)/nx_pixel, \"eV\", MCP_Position_mm_Matrix, Angular_Correction, E_Correction\n",
    "\tsetscale/P y, AzimuthLow*1.2, (AzimuthHigh-AzimuthLow)*1.2/ny_pixel, \"deg\", MCP_Position_mm_Matrix, Angular_Correction\n",
    "\n",
    "\t// energy correction? What does it do? Seems to be strictly linear...\n",
    "\t// back-calculation of the pixel position from the energy in the w_E wave. Used for the proper interpolation later\n",
    "\t//E_Correction = limit( round( (w_E- Ek)/Ep/de1 / magnification/(PixelSize*Binning) + nx_pixel/2 + E_Offset_px)  , 0, nx_pixel)\n",
    "\t// no rounding for proper interpolation\n",
    "\t//E_Correction = (w_E- Ek)/Ep/de1 / magnification/(PixelSize*Binning) + nx_pixel/2 + E_Offset_px\n",
    "\tE_Correction = (x- Ek)/Ep/de1 / magnification/(PixelSize*Binning) + nx_pixel/2 + E_Offset_px\n",
    "\t// this is a Matrix with the mm-position for the energies and angles. This uses all the calibration parameters.\n",
    "\tMCP_Position_mm_Matrix = MCP_Position_mm( x, y )\n",
    "\t// Matrix that stores pixel position in the angular row for all energies and angles\n",
    "\t//Angular_Correction[][] = limit( round( MCP_Position_mm_Matrix(p)(q)/magnification/(PixelSize*Binning) + ny_pixel/2 + Ang_Offset_px)  , 0, ny_pixel)\n",
    "\t// do proper interpolation later\n",
    "\tAngular_Correction[][] = MCP_Position_mm_Matrix[p][q]/magnification/(PixelSize*Binning) + ny_pixel/2 + Ang_Offset_px\n",
    "\t\n",
    "\tStr=\"LensMode:;Ek:;PE:;Binning:\"\n",
    "\tStr=ReplaceNumberByKey(\"LensMode\", Str, LensMode)\n",
    "\tStr=ReplaceNumberByKey(\"Ek\", Str, Ek)\n",
    "\tStr=ReplaceNumberByKey(\"PE\", Str, Ep)\n",
    "\tStr=ReplaceNumberByKey(\"Binning\", Str, binning)\n",
    "\tNote/K Angular_Correction, Str\n",
    "\t\n",
    "\tstring temp = note(Angular_correction)\n",
    "\t// calculate the Jacobian determinant for Normalization\n",
    "\tduplicate/o Angular_Correction, Jacobian_Determinant, w_dxdE, w_dxdA, w_dydE, w_dydA\n",
    "\t// Energy derivative of angular correction\n",
    "\tdifferentiate/DIM=0 w_dydE\n",
    "\t// angular derivative of angular correction\n",
    "\tdifferentiate/DIM=1 w_dydA\n",
    "\t// energy derivative of energy correction\n",
    "\tduplicate/o E_correction, w_temp\n",
    "\tdifferentiate w_temp\n",
    "\tw_dxdE = w_temp[p]\n",
    "\t// angular derivative of energy correction is flat\n",
    "\tw_dxdA = 0\n",
    "\tJacobian_Determinant = abs(w_dxdE*w_dydA - w_dydE*w_dxdA)\n",
    "\tkillWaves/z w_dxdE, w_dxdA, w_dydE, w_dydA, w_temp\n",
    "\t\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" NVAR PixelSize, magnification, E_Offset_px, Ang_Offset_px, LensMode, Ek, Ep, De1, aInner\n",
    "\tNVAR EkinLow, EkinHigh, AzimuthLow, AzimuthHigh\n",
    "\tNVAR Binning\n",
    "\tNVAR Edge_pos, Edge_Slope\n",
    "\t\n",
    "\tString Str\n",
    "\t// for full frames, if cropped in program we need to do something else?\n",
    "\tVariable nx_pixel=1376/Binning, ny_pixel=1040/Binning\n",
    "\tMake/O/N=(nx_pixel, ny_pixel) MCP_Position_mm_Matrix=NaN, Angular_Correction=NaN\n",
    "\tMake/O/N=(nx_pixel) w_E, E_Correction=NaN\n",
    "\tMake/O/N=(ny_pixel) w_Ang\n",
    "\n",
    "\tVariable Edge_Coef \"\"\"\n",
    "\n",
    "\n",
    "def calculate_matrixcorrection(ek,angle,dapolymatrix,de1,erange,arange,ainner,nx_pixel,ny_pixel,pixelsize,binning,magnification):\n",
    "\tres=1\n",
    "\treturn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" //~~~~~~~~~~~~~~~~~All the parameters needed to do the angular correction\n",
    "//\tLensMode\t\t\tfrom user\n",
    "//\tEk\t\t\t\t\tfrom user\n",
    "//\tEp\t\t\t\t\tfrom user\n",
    "//\tE_Offset_px\t\t\tfrom user\n",
    "//\tAng_Offset_px\t\tfrom user\n",
    "//\tBinning\t\t\t\tfrom user\n",
    "//\tEdge_pos\t\t\tfrom user\n",
    "//\tEdge_Slope\t\t\tfrom user\n",
    "//\teShift\t\t\t\tfrom phoibos100.Calib2D\n",
    "//\teRange\t\t\t\tfrom phoibos100.Calib2D\n",
    "//\taRange\t\t\t\tfrom phoibos100.Calib2D\n",
    "//\tDe1\t\t\t\t\tfrom phoibos100.Calib2D\n",
    "//\taInner\t\t\t\tfrom phoibos100.Calib2D\n",
    "//\tDa3 - Da7\t\t\tfrom phoibos100.Calib2D\n",
    "//\tWF\t\t\t\t\t4.2eV or from CCDAcquire\n",
    "//\tPixelSize\t\t\t0.00645 or from CCDAcquire\n",
    "//\tmagnification\t\t\t4.54 or from CCDAcquire\n",
    "//~~~~~~~~~~~~~~~~~All the parameters needed to do the angular correction \"\"\"\n",
    "\n",
    "\n",
    "specsdictionary = {\n",
    "  \"lensmode\": \"WAM\",\n",
    "  \"ek\": 12,\n",
    "  \"ep\": 20,\n",
    "  \"E_Offset_px\" : 12\n",
    "}\n",
    "specsdictionary[\"lensmode\"]\n",
    "\n",
    "\n",
    "\n",
    "#here's a good way to create a dictionary from the info txt\n",
    "def get_pair(line):\n",
    "    key, sep, value = line.strip().partition(\":\")\n",
    "    return key, value\n",
    "\n",
    "with open(infofilename) as fd:    \n",
    "    d = dict(get_pair(line) for line in fd)\n",
    "\n",
    "d[\"ScanType\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ebc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a586bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the package regex seems to be the one for analysing the calib2d\n",
    "#check this out\n",
    "#  https://stackoverflow.com/questions/4146009/python-get-list-indexes-using-regular-expression\n",
    "\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15027904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('specanalyserenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "01f3a50f1cec8b32686da9a100309d20236977f5c6d2fb4bd4818f1295405c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
